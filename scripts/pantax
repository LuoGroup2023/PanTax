#!/bin/bash

set -e
function print_help() {
  echo "Usage: $0 -f genomes_info -s/-l -r read.fq [option]"
  echo "       paired-end: $0 -f genomes_info -s -p -r read.fq --species-level"
  echo ""
  echo "Strain-level taxonomic classification of metagenomic data using pangenome graphs"
  echo ""
  echo "Author: Weihai Zhang"
  echo "Date:   May 2024"
  echo ""
  echo "    General options:"
  echo "        -f, --genomesInformation str:     A list of reference genomes in specified format (Mandatory)."
  echo "        -db str                           Name for pantax DB (default: pantax_db)."
  echo "        -T str                            Temporary directory (default: pantax_db_tmp)."
  echo "        -n, --next                        Keep the temporary folder for later use at the strain level (resume)." 
  echo "        -t, --threads INT                 Number of processes to run in parallel(default: all available)."
  echo "        -v, --verbose                     Detailed database build log."
  echo "        --vg str                          Path to vg executable file."
  echo "        --debug                           Keep the temporary folder for any situation."
  echo "        --help, -h                        Print this help message."
  echo "        --version                         Print the version info."
  echo "    Database creation:"
  echo "        --create                          Create database only."
  echo "        --force                           Force to rebuild pangenome."
  echo "        -e                                Path to pangenome building tool executable file (default: pggb)." 
#   echo "        --parallel str                    Multiple species at once (default: True/on)."
  echo "    Index construction(for short read):"
  echo "        --index                           Create index only."
  echo "        --best                            Best autoindex(only used with -s)."
  echo "        --fast                            Fast index(only used with -l)."
  echo "    Read alignment:"
  echo "        -r, --fastq-in str                Read and align FASTQ-format reads from FILE (two are allowed with -p)."
  echo "        -s, --short-read                  Short read alignment."
  echo "        -p, --paired                      For paired-end alignment."
  echo "        -l, --long-read                   Long read alignment."
  echo "    Abundacnce calculation:"
  echo "        --species-level                   Species abundance calulation."
  echo "        --strain-level                    Strain abundance calulation."
  echo "        -a float                          Species with more than abundance threshold used for strain abundance calulation.(default: 0.0001)."
  echo "        -fr float                         Unique trio nodes fraction(default: 0.3)."
  echo "        -fc float                         Unique trio nodes mean count fraction(default: 0.45)."
#   echo "        --filter str                      MAPQ-based filter (default: True/on)."
  echo "        --min_cov int                     Minimum coverage required per strain(default: 0)."
  echo "        --min_depth int                   Graph nodes with sequence depth less than <min_depth>(default: 0)."
  echo "        -gt int                           Gurobi threads(default: 1)."
  echo "        -g, --save                        Save species graph information."
  echo "        -S, --classified-out str          File for alignment output(prefix)."
  echo "        -R, --report str                  File for read classification output(prefix)."
  echo "        -o, --ouput str                   File for abundance output(prefix)."
#   echo "    Other:"
#   echo "        --sample                          Sampling nodes(500) are used for small model testing (set for codeocean)."
  echo ""
  exit 0
}

timestamp=$(date "+%Y-%m-%d %H:%M:%S")
echo "$timestamp - $0 $@"

# set default value
version="v1.1.0"
# General
genomes_info=""
pantax_db="pantax_db"
tmp_dir=""
next_for_strain="False"
threads=$(grep -c ^processor /proc/cpuinfo)
verbose="False"
vg=""
debug="False"

# Database creation
create_db="False"
force="False"
pangenome_building_tool="pggb"
parallel_build="True"

create_index="False"
short_read_best_alignment="False"
long_read_fast_alignment="False"

short_reads="False"
long_reads="False"
pair_short_read="False"

species_level_flag="False"
strain_level_flag="False"
isfilter=1
save=0
species_abund_threshold=0.0001
unique_trio_nodes_fraction=0.3
unique_trio_nodes_count=0.45
min_cov=0
min_depth=0
sample=0
gurobi_threads=1

wd=$(pwd)
interleaved_short_read="False"
input_fq=""
input_fq1=""
input_fq2=""
pantax_report=pantax_report.tsv
#Print help if no argument specified
if [[ "$1" == "" ]]; then
  print_help
fi

# get parameters
while [[ "$1" != "" ]]; do
    case "$1" in
        "-f" | "--genomesInformation") [[ -z "$2" ]] && { echo "Error: $1 expects an argument"; exit 1; } || { genomes_info="$2"; shift 2; } ;;
        "-db") [[ -z "$2" ]] && { echo "Error: $1 expects an argument"; exit 1; } || { pantax_db="$2"; shift 2; } ;;
        "-T") [[ -z "$2" ]] && { echo "Error: $1 expects an argument"; exit 1; } || { tmp_dir="$2"; shift 2; } ;;
        "-n" | "--next") next_for_strain="True"; shift 1;;
        "-t" | "--threads") [[ -z "$2" ]] && { echo "Error: $1 expects an argument"; exit 1; } || { threads=$2; shift 2; } ;;
        "-v" | "--verbose") verbose="True"; shift 1 ;;
        "--vg") [[ -z "$2" ]] && { echo "Error: $1 expects an argument"; exit 1; } || { vg="$2"; shift 2; } ;;
        "--debug") debug="True"; shift 1;;
        "--help" | "-h") print_help;;
        "--version") echo $version; exit 0;;

        "--create") create_db="True"; shift 1;;
        "--force") force="True"; shift 1;;
        "-e") [[ -z "$2" ]] && { echo "Error: $1 expects an argument"; exit 1; } || { pangenome_building_tool="$2"; shift 2; } ;;
        "--parallel") parallel_build=$2; shift 2;;

        "--index") create_index="True"; shift 1;;
        "--best") short_read_best_alignment="True"; shift 1;;
        "--fast") long_read_fast_alignment="True"; shift 1;;  

        "-s" | "--short-read") short_reads="True"; shift 1;;
        "-p" | "--paired") pair_short_read="True"; shift 1;;
        "-l" | "--long-read") long_reads="True"; shift 1;;   
        "-r" | "--fastq-in")
            [[ -z "$2" ]] && { echo "Error: $1 expects an argument"; exit 1; }
            if [[ -z $input_fq ]] && [ $pair_short_read == "False" ]; then
                input_fq=$2 
            elif [[ $pair_short_read == "True" ]] && ( [[ -z $input_fq1 ]] || [[ -z $input_fq2 ]] ); then
                if [ -z $input_fq1 ]; then
                    input_fq1="$2"
                elif [ -z $input_fq2 ]; then
                    input_fq2="$2"
                fi
            else
                echo "Error: Too many -r/--fastq-in arguments"
                exit 1
            fi
            shift 2
            ;;

        "--strain-level") strain_level_flag="True"; shift 1;;
        "--species-level") species_level_flag="True"; shift 1;;
        "--filter") isfilter=$2; shift 2;;
        "-a") [[ -z "$2" ]] && { echo "Error: $1 expects an argument"; exit 1; } || { species_abund_threshold="$2"; shift 2; } ;;
        "-fr") [[ -z "$2" ]] && { echo "Error: $1 expects an argument"; exit 1; } || { unique_trio_nodes_fraction="$2"; shift 2; } ;;   
        "-fc") [[ -z "$2" ]] && { echo "Error: $1 expects an argument"; exit 1; } || { unique_trio_nodes_count="$2"; shift 2; } ;;    
        "--min_cov") [[ -z "$2" ]] && { echo "Error: $1 expects an argument"; exit 1; } || { min_cov="$2"; shift 2; } ;;
        "--min_depth") [[ -z "$2" ]] && { echo "Error: $1 expects an argument"; exit 1; } || { min_depth="$2"; shift 2; } ;;
        "-g" | "--save") save=1; shift 1;;                
        "-S" | "--classified-out") [[ -z "$2" ]] && { echo "Error: $1 expects an argument"; exit 1; } || { read_aln="$2".gaf; shift 2; } ;;                                                                          
        "-R" | "--report") [[ -z "$2" ]] && { echo "Error: $1 expects an argument"; exit 1; } || { pantax_report="$2".tsv; shift 2; } ;;
        "-o" | "--output") [[ -z "$2" ]] && { echo "Error: $1 expects an argument"; exit 1; } || { pantax_output=$2; shift 2; } ;;
        "-gt") [[ -z "$2" ]] && { echo "Error: $1 expects an argument"; exit 1; } || { gurobi_threads=$2; shift 2; } ;;                                                             

        "--sample") sample=1; shift 1;;

        --) shift; break;;
        *) echo "Error: invalid option \"$1\""; exit 1;;
    esac
done

if [ ! -d $pantax_db ]; then
    mkdir $pantax_db
elif [ -d $pantax_db ] && [ $force == "True" ]; then
    rm -rf $pantax_db
    mkdir $pantax_db
fi
pantax_db=$(readlink -f $pantax_db)

if [ ! -z $genomes_info ] && [ -f $genomes_info ]; then
    genomes_info=$(readlink -f $genomes_info)
elif [ -z $genomes_info ] && [ -f $pantax_db/genomes_info.txt ]; then
    genomes_info=$(readlink -f $pantax_db/genomes_info.txt)
elif [ $create_db == "False" ] && [ $create_index == "True" ]; then
    :
else
    echo "genomes information file does not exist!"
    exit 1
fi

if [ $parallel_build == "False" ] || [ $parallel_build == "false" ] || [ $parallel_build == "off" ]; then
    parallel_build="False"
else 
    parallel_build="True"
fi

if [ $create_db == "False" ] && [ $create_index == "False" ]; then
    if [ ! -z $input_fq ] && [ -f $input_fq ]; then
        input_fq=$(readlink -f $input_fq)
    elif [ ! -z $input_fq1 ] && [ -f $input_fq1 ] && [ ! -z $input_fq2 ] && [ -f $input_fq2 ]; then
        input_fq1=$(readlink -f $input_fq1)
        input_fq2=$(readlink -f $input_fq2)
        interleaved_short_read="False"
    elif [ ! -z $input_fq1 ] && [ -f $input_fq1 ] && [ -z $input_fq2 ]; then
        input_fq1=$(readlink -f $input_fq1)
        input_fq=$input_fq1
        input_fq1=""
        interleaved_short_read="True"        
    else
        echo "fastq file does not exist!"
        exit 1    
    fi

    if [ $isfilter == 0 ] || [ $isfilter == "off" ]; then
        isfilter_flag=0
    else 
        isfilter_flag=1
    fi

    echo "Main parameters settings:"
    echo "  threads: $threads"
    echo "Database creation:"
    echo "  genomes_info: $genomes_info"
    echo "  pantax_db: $pantax_db"
    echo "Index construction:"
    if [ $short_reads == "True" ]; then
        echo "  short_reads: $short_reads"
    elif [ $long_reads == "True" ]; then
        echo "  long_reads: $long_reads"
    else 
        echo "No read type!"
        exit 1
    fi
    echo "Read classification:"
    echo "  input_fq: $input_fq"
    echo "  input_fq1: $input_fq1"
    echo "  input_fq2: $input_fq2"
    echo "  strain_level_flag: $strain_level_flag"
    echo "  species_level_flag: $species_level_flag"
    if [ $strain_level_flag == "False" ] && [ $species_level_flag == "False" ]; then
        echo "No species or strain option specified. Please set --species-level or --strain-level."
        exit 1
    fi
fi

# some tools work in different directory when install with conda or from source.
if [[ $(which $0) == *conda* ]]; then
    conda_run_flag="True"
else 
    conda_run_flag="False"
fi
# set tools working path
script_path=$(readlink -f $0)
script_dir=$(dirname $script_path)
if [ $conda_run_flag == "True" ]; then
    # tools_dir=$script_dir/tools
    tools_dir=$script_dir
    fastix=$tools_dir/fastix
else
    tools_dir=$(dirname $script_dir)/tools
    fastix=$tools_dir/fastix/bin/fastix
fi
if [ ! -z $vg ] && [ -f $vg ]; then
    :
elif [ -z $vg ]; then
    vg=$tools_dir/vg
fi

# tmp
if [ -z $tmp_dir ]; then
    tmp_dir=$(basename $pantax_db)_tmp
    tmp_dir=$(readlink -f $tmp_dir)
elif [ ! -z $tmp_dir ] && [ -d $tmp_dir ]; then
    tmp_dir=$tmp_dir/${pantax_db}_tmp
elif [ ! -z $tmp_dir ] && [ ! -d $tmp_dir ]; then
    :
fi
if [ $next_for_strain == "False" ] && [ $debug == "False" ]; then
    rm -rf $tmp_dir
fi
mkdir -p $tmp_dir
cd $tmp_dir

cleanup() {
    echo "$(date "+%Y-%m-%d %H:%M:%S") - PanTax encountered an exception while running and has deleted the tmp folder."
    echo "If you need to start checking not to delete the tmp directory, please add the --debug option."
    rm -rf $tmp_dir
}
if [ $debug == "False" ]; then
    trap cleanup ERR
fi

# ---------------------------- Building reference pangenome ----------------------------
if [ ! -f $pantax_db/reference_pangenome.gfa ]; then 
    # backup genomes_info for each custom database
    cp -f $genomes_info $pantax_db/genomes_info.txt
    new_pantax_db=$pantax_db
    pantax_db=$tmp_dir
    reconstruction_flag="True"
else
    reconstruction_flag="False"
fi

if [ ! -f $pantax_db/reference_pangenome.gfa ] && [ $create_index == "True" ]; then
    echo "$pantax_db/reference_pangenome.gfa does not exist."
fi

if [ $reconstruction_flag == "True" ]; then 
    echo "$(date "+%Y-%m-%d %H:%M:%S") - Building reference pangenome ..."
    # Prepare genomes information. Return species_pangenome directory and species_eq1_genomes.txt
    # Species(in species_pangenome directory) more than 2 genomes will be used to build pangenome firstly.
    python $script_dir/prepare_building.py $genomes_info $wd $tmp_dir
    gfa_build_dir=$tmp_dir/gfa_build
    # first step: build pangenome for the species with more than two genomes
    python $script_dir/task_scheduling.py $gfa_build_dir $tmp_dir/species_pangenome $fastix $vg -t $threads -v $verbose -f $force -e $pangenome_building_tool -d $debug -p $parallel_build

    # second step: build variation graph for the species with one genomes
    python $script_dir/build_graph.py species_eq1_genomes.txt $gfa_build_dir
    if [ $debug == "False" ]; then
        rm -rf $tmp_dir/species_pangenome $tmp_dir/species_eq1_genomes.txt
    fi
    cat $gfa_build_dir/gfa_build_done.txt | xargs -I {} -P $(($threads/2)) bash -c 'vg=$1; gfa_build_dir=$2; input=$3; name=$(basename $input .gfa); output=$gfa_build_dir/$name.vg; $vg convert -g $input -p > $output' _ $vg $gfa_build_dir {}
    vg_files=$(ls $gfa_build_dir/*.vg)
    $vg combine -p $vg_files > reference_pangenome.vg
    $vg convert -f reference_pangenome.vg > reference_pangenome.gfa
    if [ $debug == "False" ]; then
        rm reference_pangenome.vg $vg_files
    fi
    python $script_dir/otu_range.py reference_pangenome.gfa $genomes_info --species-level
    # extract gfa files for strain abundance computing
    mkdir -p $tmp_dir/species_gfa
    find $gfa_build_dir -name "*gfa" -exec bash -c 'input=$1; tmp_dir=$2; name=$(basename $input); mv $input $tmp_dir/species_gfa/' _ {} $tmp_dir \;
    mv $tmp_dir/species_gfa reference_pangenome* species_range.txt $new_pantax_db
    pantax_db=$new_pantax_db
    echo "$(date "+%Y-%m-%d %H:%M:%S") - Building reference pangenome completely."
else
    echo "$(date "+%Y-%m-%d %H:%M:%S") - Reference_pangenome.gfa exists. Skipping."
fi

if [ $create_db == "True" ] && [ $create_index == "False" ];then
    cd ..
    if [ $debug == "False" ]; then
        rm -rf $tmp_dir
    fi
    exit 0
fi

if [ $create_index == "True" ] && [ ! -e $pantax_db/reference_pangenome.min ] && [ ! -e $new_pantax_db/reference_pangenome.min ]; then
    echo "$(date "+%Y-%m-%d %H:%M:%S") - Construct index...."
    if [ $short_read_best_alignment == "False" ]; then
        # # these commands all can show progress with option -p
        $vg gbwt -g reference_pangenome.giraffe.gbz --gbz-format -G $pantax_db/reference_pangenome.gfa
        $vg index -j reference_pangenome.dist reference_pangenome.giraffe.gbz -t $threads
        $vg minimizer -d reference_pangenome.dist -o reference_pangenome.min reference_pangenome.giraffe.gbz
    else
        $vg autoindex -p reference_pangenome -w giraffe -g $pantax_db/reference_pangenome.gfa -t $threads
    fi
    mv reference_pangenome* $pantax_db    
    echo "$(date "+%Y-%m-%d %H:%M:%S") - Construct index.... done"
else
    echo "$(date "+%Y-%m-%d %H:%M:%S") - Giraffe index exists. Skipping." 
fi

if [ $create_index == "True" ];then
    cd ..
    if [ $debug == "False" ]; then
        rm -rf $tmp_dir
    fi
    exit 0
fi

# ---------------------------- Reads alignment ----------------------------
# short reads alignment(the latest vg giraffe can be used for long reads)
if [[ ( $species_level_flag == "True" || $strain_level_flag == "True" ) && ( $short_reads == "True" || $long_read_fast_alignment == "True" ) && ! -f gfa_mapped.gaf ]]; then
    echo "$(date "+%Y-%m-%d %H:%M:%S") - Reads alignment with vg giraffe."    
    # this step produce three index files: reference_pangenome.giraffe.gbz, reference_pangenome.dist, reference_pangenome.min.
    # default mode(quick)
    if [ $reconstruction_flag == "True" ] || [ ! -e $pantax_db/reference_pangenome.min ]; then
        echo "$(date "+%Y-%m-%d %H:%M:%S") - Construct index...."
        if [ $short_read_best_alignment == "False" ] && [ ! -e $pantax_db/reference_pangenome.min ]; then
            # # these commands all can show progress with option -p
            $vg gbwt -g reference_pangenome.giraffe.gbz --gbz-format -G $pantax_db/reference_pangenome.gfa
            $vg index -j reference_pangenome.dist reference_pangenome.giraffe.gbz
            $vg minimizer -d reference_pangenome.dist -o reference_pangenome.min reference_pangenome.giraffe.gbz
        else
            $vg autoindex -p reference_pangenome -w giraffe -g $pantax_db/reference_pangenome.gfa -t $threads
        fi
        mv reference_pangenome* $pantax_db
    fi
    echo "$(date "+%Y-%m-%d %H:%M:%S") - vg giraffe mapping..."
    # $vg giraffe -Z reference_pangenome.giraffe.gbz -m reference_pangenome.min -d reference_pangenome.dist -i -f $input_fq -t $threads --named-coordinates > gfa_mapped.gam
    # $vg convert -a gfa_mapped.gam -j > gfa_mapped.json
    if [ $pair_short_read == "True" ] && [ $interleaved_short_read == "True" ]; then
        $vg giraffe -Z $pantax_db/reference_pangenome.giraffe.gbz -m $pantax_db/reference_pangenome.min -d $pantax_db/reference_pangenome.dist -i -f $input_fq -t $threads --named-coordinates -o gaf > gfa_mapped.gaf
    elif [ $pair_short_read == "True" ] && [ $interleaved_short_read == "False" ]; then
        $vg giraffe -Z $pantax_db/reference_pangenome.giraffe.gbz -m $pantax_db/reference_pangenome.min -d $pantax_db/reference_pangenome.dist -f $input_fq1 -f $input_fq2 -t $threads --named-coordinates -o gaf > gfa_mapped.gaf
    elif [ $pair_short_read == "False" ]; then
        $vg giraffe -Z $pantax_db/reference_pangenome.giraffe.gbz -m $pantax_db/reference_pangenome.min -d $pantax_db/reference_pangenome.dist -f $input_fq -t $threads --named-coordinates -o gaf > gfa_mapped.gaf
    fi
fi

# long reads alignment
if [ $species_level_flag == "True" ] && [ $long_reads == "True" ] && [ $long_read_fast_alignment == "False" ] && [ ! -f gfa_mapped.gaf ]; then
    echo "$(date "+%Y-%m-%d %H:%M:%S") - Reads alignment with Graphaligner..."
    GraphAligner -g $pantax_db/reference_pangenome.gfa -f $input_fq -a gfa_mapped.gaf -x vg -t $threads
    python $script_dir/gaf_filter.py -i gfa_mapped.gaf
    mv gfa_mapped_filtered.gaf gfa_mapped.gaf
fi

# ---------------------------- Reads classification(binning) ----------------------------
if [ $species_level_flag == "True" ] && [ -f "gfa_mapped.gaf" ] && [ -f $pantax_db/species_range.txt ]; then
    echo "$(date "+%Y-%m-%d %H:%M:%S") - Read classification..."
    # python $script_dir/read_classification2.py species_range.txt gfa_mapped.json
    python $script_dir/read_classification.py -s $pantax_db/species_range.txt -m gfa_mapped.gaf 
fi

# ---------------------------- species level binning and profiling ----------------------------
if [ $species_level_flag == "True" ]; then
    echo "$(date "+%Y-%m-%d %H:%M:%S") - Species abundance estimation..."
    if [ $short_reads == "True" ]; then
        python $script_dir/species_abundance_cal.py $genomes_info reads_classification.csv short -ft $isfilter_flag $wd
    elif [ $long_reads == "True" ]; then
        python $script_dir/species_abundance_cal.py $genomes_info reads_classification.csv long -ft $isfilter_flag $wd
    fi
fi 

# ---------------------------- strain level binning and profiling ----------------------------
if [ $strain_level_flag == "True" ]; then
    echo "$(date "+%Y-%m-%d %H:%M:%S") - Strain abundance estimation..."
    if [ $verbose == "True" ]; then
        python $script_dir/strain_abundance_cal.py -a $species_abund_threshold -fr $unique_trio_nodes_fraction -fc $unique_trio_nodes_count -c $min_cov -d $min_depth -t $threads -gt $gurobi_threads -s $save --sample $sample -v $pantax_db $genomes_info reads_classification.csv gfa_mapped.gaf $pantax_db/species_range.txt species_abundance.txt 
    else
        python $script_dir/strain_abundance_cal.py -a $species_abund_threshold -fr $unique_trio_nodes_fraction -fc $unique_trio_nodes_count -c $min_cov -d $min_depth -t $threads -gt $gurobi_threads -s $save --sample $sample $pantax_db $genomes_info reads_classification.csv gfa_mapped.gaf $pantax_db/species_range.txt species_abundance.txt 
    fi
    if [ $save == 1 ]; then
        if [ $reconstruction_flag == "False" ]; then
            mv species_graph_info $pantax_db
        else
            mv species_graph_info $new_pantax_db
        fi
    fi
fi

# move and rename files
cd ..
if [ $species_level_flag == "True" ]; then
    cp $tmp_dir/species_abundance.txt $wd
    if [ $pantax_output ]; then
        specie_abund_file=${pantax_output}_species_abundance.txt
        mv $wd/species_abundance.txt $specie_abund_file         
    fi
fi
if [ $strain_level_flag == "True" ]; then
    cp $tmp_dir/strain_abundance.txt $wd
    if [ $pantax_output ]; then
        strain_abund_file=${pantax_output}_strain_abundance.txt
        mv $wd/strain_abundance.txt $strain_abund_file
    fi
fi

# if next_for_strain is true, we will save tmp files for strain level profiling.
if [[ ( $strain_level_flag == "True" && $next_for_strain == "True" ) || ( $species_level_flag == "True" && $next_for_strain == "False" ) ]]; then
    if [ $read_aln ]; then
        mv $tmp_dir/gfa_mapped.gaf $wd
        mv $wd/gfa_mapped.gaf $read_aln
    fi

    cp $tmp_dir/reads_classification.csv $wd
    mv $wd/reads_classification.csv $pantax_report
    if [ $debug == "False" ]; then
        mv $tmp_dir/reads_classification.csv $wd
        mv $wd/reads_classification.csv $pantax_report
        rm -rf $tmp_dir
    fi
fi
echo "$(date "+%Y-%m-%d %H:%M:%S") - PanTax Done."